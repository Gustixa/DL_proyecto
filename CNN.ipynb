{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f651b34a-ab90-4b88-b934-6464edd35c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2b19a7-c983-40c1-8e08-c00f1caf3699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_fName</th>\n",
       "      <th>img_w</th>\n",
       "      <th>img_h</th>\n",
       "      <th>bbx_xtl</th>\n",
       "      <th>bbx_ytl</th>\n",
       "      <th>bbx_xbr</th>\n",
       "      <th>bbx_ybr</th>\n",
       "      <th>class_label</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_00000.jpeg</td>\n",
       "      <td>2448</td>\n",
       "      <td>3264</td>\n",
       "      <td>1301</td>\n",
       "      <td>1546</td>\n",
       "      <td>1641</td>\n",
       "      <td>2096</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_00000.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_00001.jpeg</td>\n",
       "      <td>3024</td>\n",
       "      <td>4032</td>\n",
       "      <td>900</td>\n",
       "      <td>1897</td>\n",
       "      <td>1950</td>\n",
       "      <td>2990</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_00001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_00002.jpeg</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>220</td>\n",
       "      <td>58</td>\n",
       "      <td>659</td>\n",
       "      <td>808</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_00002.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_00003.jpeg</td>\n",
       "      <td>3456</td>\n",
       "      <td>4608</td>\n",
       "      <td>1169</td>\n",
       "      <td>2364</td>\n",
       "      <td>1586</td>\n",
       "      <td>2826</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_00003.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_00004.jpeg</td>\n",
       "      <td>1024</td>\n",
       "      <td>1365</td>\n",
       "      <td>129</td>\n",
       "      <td>231</td>\n",
       "      <td>697</td>\n",
       "      <td>1007</td>\n",
       "      <td>culex</td>\n",
       "      <td>./phase2_train_v0/final/train_00004.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>train_10352.jpeg</td>\n",
       "      <td>2064</td>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>1344</td>\n",
       "      <td>1253</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_10352.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>train_10353.jpeg</td>\n",
       "      <td>2664</td>\n",
       "      <td>3996</td>\n",
       "      <td>821</td>\n",
       "      <td>1481</td>\n",
       "      <td>1564</td>\n",
       "      <td>2706</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_10353.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>train_10354.jpeg</td>\n",
       "      <td>1157</td>\n",
       "      <td>1157</td>\n",
       "      <td>367</td>\n",
       "      <td>315</td>\n",
       "      <td>676</td>\n",
       "      <td>764</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_10354.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>train_10355.jpeg</td>\n",
       "      <td>3000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1064</td>\n",
       "      <td>2463</td>\n",
       "      <td>1442</td>\n",
       "      <td>2917</td>\n",
       "      <td>albopictus</td>\n",
       "      <td>./phase2_train_v0/final/train_10355.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>train_10356.jpeg</td>\n",
       "      <td>1536</td>\n",
       "      <td>2048</td>\n",
       "      <td>350</td>\n",
       "      <td>641</td>\n",
       "      <td>916</td>\n",
       "      <td>1347</td>\n",
       "      <td>culex</td>\n",
       "      <td>./phase2_train_v0/final/train_10356.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10357 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_fName  img_w  img_h  bbx_xtl  bbx_ytl  bbx_xbr  bbx_ybr  \\\n",
       "0      train_00000.jpeg   2448   3264     1301     1546     1641     2096   \n",
       "1      train_00001.jpeg   3024   4032      900     1897     1950     2990   \n",
       "2      train_00002.jpeg    768   1024      220       58      659      808   \n",
       "3      train_00003.jpeg   3456   4608     1169     2364     1586     2826   \n",
       "4      train_00004.jpeg   1024   1365      129      231      697     1007   \n",
       "...                 ...    ...    ...      ...      ...      ...      ...   \n",
       "10352  train_10352.jpeg   2064   1376        0      139     1344     1253   \n",
       "10353  train_10353.jpeg   2664   3996      821     1481     1564     2706   \n",
       "10354  train_10354.jpeg   1157   1157      367      315      676      764   \n",
       "10355  train_10355.jpeg   3000   4000     1064     2463     1442     2917   \n",
       "10356  train_10356.jpeg   1536   2048      350      641      916     1347   \n",
       "\n",
       "      class_label                                image_path  \n",
       "0      albopictus  ./phase2_train_v0/final/train_00000.jpeg  \n",
       "1      albopictus  ./phase2_train_v0/final/train_00001.jpeg  \n",
       "2      albopictus  ./phase2_train_v0/final/train_00002.jpeg  \n",
       "3      albopictus  ./phase2_train_v0/final/train_00003.jpeg  \n",
       "4           culex  ./phase2_train_v0/final/train_00004.jpeg  \n",
       "...           ...                                       ...  \n",
       "10352  albopictus  ./phase2_train_v0/final/train_10352.jpeg  \n",
       "10353  albopictus  ./phase2_train_v0/final/train_10353.jpeg  \n",
       "10354  albopictus  ./phase2_train_v0/final/train_10354.jpeg  \n",
       "10355  albopictus  ./phase2_train_v0/final/train_10355.jpeg  \n",
       "10356       culex  ./phase2_train_v0/final/train_10356.jpeg  \n",
       "\n",
       "[10357 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"phase2_train_v0.csv\")\n",
    "data['image_path'] = \"./phase2_train_v0/final/\"+data['img_fName']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7e49b7-1160-4ea4-ba8a-4013de1c7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar ImageDataGenerator con aumento de datos para las clases minoritarias\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5428cda-051d-4d52-990f-b26601f106d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8286 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Crear generador de entrenamiento\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    x_col='image_path',\n",
    "    y_col='class_label',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5150dc-c881-43e6-879f-d2297764aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2071 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Crear generador de validación\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    x_col='image_path',\n",
    "    y_col='class_label',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf95a0f-02cc-4f9d-a5ae-90d9a3fc5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')  # 6 clases de especies de mosquitos\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd883790-920b-4757-9bff-6e74ff1ddd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbfca54-b4ea-4079-a754-939974c7337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el callback de TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b2915ba-2540-4384-9ac3-1fc5d55612bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el callback para reducir la tasa de aprendizaje cuando la validación no mejore\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ddb43d-013c-4a47-96be-2b7bebcb8c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.4454 - loss: 1.1927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 2s/step - accuracy: 0.4468 - loss: 1.1893 - val_accuracy: 0.5374 - val_loss: 1.0716 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 1s/step - accuracy: 0.4912 - loss: 1.1321 - val_accuracy: 0.5616 - val_loss: 1.0352 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.5649 - loss: 1.0566 - val_accuracy: 0.6263 - val_loss: 1.0168 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.5990 - loss: 1.0323 - val_accuracy: 0.6359 - val_loss: 0.9543 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 2s/step - accuracy: 0.6238 - loss: 1.0052 - val_accuracy: 0.6610 - val_loss: 0.9104 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.6545 - loss: 0.9655 - val_accuracy: 0.7103 - val_loss: 0.8408 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.6792 - loss: 0.9100 - val_accuracy: 0.7378 - val_loss: 0.7918 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.6975 - loss: 0.8588 - val_accuracy: 0.7238 - val_loss: 0.8142 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.7183 - loss: 0.8412 - val_accuracy: 0.7562 - val_loss: 0.7808 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.7248 - loss: 0.8162 - val_accuracy: 0.7533 - val_loss: 0.7475 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.7282 - loss: 0.8126 - val_accuracy: 0.7663 - val_loss: 0.7353 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.7307 - loss: 0.8057 - val_accuracy: 0.7663 - val_loss: 0.7151 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.7483 - loss: 0.7704 - val_accuracy: 0.7648 - val_loss: 0.7314 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.7598 - loss: 0.7495 - val_accuracy: 0.7648 - val_loss: 0.7325 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 1s/step - accuracy: 0.7562 - loss: 0.7538 - val_accuracy: 0.7750 - val_loss: 0.7095 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 1s/step - accuracy: 0.7643 - loss: 0.7412 - val_accuracy: 0.7731 - val_loss: 0.6911 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.7652 - loss: 0.7337 - val_accuracy: 0.7866 - val_loss: 0.6805 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.7541 - loss: 0.7467 - val_accuracy: 0.7875 - val_loss: 0.7002 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.7596 - loss: 0.7286 - val_accuracy: 0.7774 - val_loss: 0.7055 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.7674 - loss: 0.7129 - val_accuracy: 0.7764 - val_loss: 0.6970 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con el callback de reducción de tasa de aprendizaje\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[tensorboard_callback, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba8312a-778d-43aa-b6a9-d6ba90de6a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 894ms/step - accuracy: 0.7666 - loss: 0.7179\n",
      "Accuracy: 0.7783679366111755\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdec3217-778b-4f42-a1a9-092e18e3ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo en un archivo .h5\n",
    "model.save(\"modelo_mosquitos.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e2626-5eb2-42a1-aefd-63b5b0e8ef7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
